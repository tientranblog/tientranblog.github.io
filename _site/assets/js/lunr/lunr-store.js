var store = [{
        "title": "Building a AWS Machine Learning Course Interactive Dashboard",
        "excerpt":"Business Scenario   The training organization has 46 videos covering various Machine Learning topics. The project aims to develop a user-friendly dashboard that enables students to easily find relevant video content based on their search queries.   Techniques  a. Speech-to-text     ffmpeg: video and audio processing.   MoviePy: video editing and manipulation.   OpenAI Whisper: speech-to-text conversion. b. Text normalization   NLTK: text processing and analysis. c. Keyphrase extraction   Transformers: natural language processing tasks like keyphrase extraction. This technique uses a pre-trained keyphrase extraction model (ml6team/keyphrase-extraction-kbir-inspec) from the Hugging Face Transformers library. This model is likely based on a BERT-like architecture and is trained to identify important keyphrases within text. d. Data handling   Pandas: Used for data loading, storage, and manipulation. The transcribed text, keyphrases, and other information are likely stored in Pandas DataFrames for efficient processing and analysis. e. Data visualization   WordCloud: generating word clouds.   Bokeh: interactive visualizations. This library is used to create interactive visualizations like bar charts, word clouds, and annular wedges. These visualizations help to present information about the video content, keyphrases, and topics in an engaging and understandable way.   Workflow   1. Data Acquisition and Preprocessing  a. Video to Audio Conversion:  Convert the MP4 video files to MP3 audio files using ffmpeg or moviepy.  b. Speech-to-Text Transcription:  Use the OpenAI Whisper model to transcribe the audio files into text and save the transcripts as text files.  c. Create DataFrame:  Load the transcripts into a Pandas DataFrame, associating each transcript with its corresponding video name.  d. Data Cleaning and Normalization:  Apply text normalization techniques (lowercasing, lemmatization, removing non-ASCII characters, URLs, emojis, punctuation, numbers, and stop words) to clean and prepare the transcripts for further analysis.  e. Add Metadata:  Extract video module information and calculate text length to enrich the DataFrame.   2. Keyphrase Extraction  a. Initialize Keyphrase Extractor:  Load the pre-trained keyphrase extraction model (ml6team/keyphrase-extraction-kbir-inspec).  b. Extract Keyphrases:  Apply the keyphrase extractor to the normalized transcripts to identify important keyphrases for each video.  c. Refine Keyphrases:  Perform further refinement on extracted keyphrases, such as replacing common abbreviations with their full forms and lemmatizing.   3. Data Organization and Analysis  a. Create Keyword Dictionary:  Build a dictionary mapping keyphrases to their corresponding video names to facilitate search functionality.  b. Create Keyword DataFrame:  Convert the keyword dictionary into a Pandas DataFrame for easier analysis and manipulation.  c. Calculate Keyword Frequency:  Determine the frequency of each keyphrase across all videos.  d. Filter Keyphrases:  Apply criteria based on keyword length, character count, and frequency to filter out less relevant or redundant keyphrases.   4. Dashboard Creation and Visualization  a. Create Visualization Components:  Use Bokeh to build interactive visualizations, such as bar charts to show video count and average text length by module, word clouds to display frequent keyphrases, annular wedges to represent topic distribution within modules, and a horizontal bar chart to visualize text length for each video.  b. Create Filterable Table:  Implement a searchable and filterable table using Bokeh to display keyphrases and their associated videos.  c. Assemble Dashboard Layout:  Arrange the visualization components and table within a Bokeh layout to create the final dashboard.  d. Display Dashboard:  Show the dashboard using the show() function from Bokeh, allowing users to interact with the visualizations and search for video content using keyphrases.   Functionalities  a. Compare modules    b. WordClouds    c. List Main Topics    d. Compare Text Length    e. Search Keywords       Demo     ","categories": [],
        "tags": [],
        "url": "/projects/project-Building%20a%20AWS%20Machine%20Learning%20Course%20Interactive%20Dashboard/",
        "teaser": "/assets/obsidian/9ff33e130373914fe50742562984fb89.png"
      },{
        "title": "Building a classification model to predict type-2 diabetes",
        "excerpt":"Business Scenario   Diabetes is a common chronic disease caused by increasing blood sugar level in the body above a certain threshold. Diabetes is classified into type-1 and type-2, in which type-2 diabetes patients account for the majority number of total diabetes patients. Early detection is very important because it helps to reduce complications and minimize death rate.  Therefore, this app is aim to build a machine learning classification model to predict type-2 diabetes.   Techniques      Download data from URL and extract data: requests, zipfile   Data manipulation: pandas, numpy   Data Visualization: matplotlib, seaborn   Handling imbalanced datasets: imbalanced-learn   Encoding, scaling features, model training: scikit-learn   Model deploying via web app: streamlit   Workflow   1. Data Collection     Download and Extract Data: Dataset is downloaded from Behavioral Risk Factor Surveillance System (BRFSS) 2022, which was released on July 07, 2023. BRFSS is one of the biggest on-going health-related telephone surveys system in the world, which collects health-related risk behavior, chronic health issues and other data from people more than 18 years old living in the US and participating US territories annually.   Selects specific columns relevant to the analysis: We select 15 features related to diabetes in the original dataset to analyze, in which DIABETE4 is output and 14 remaining attributes are input.    Maps categorical values to more readable labels: because original data is represented in number value, we map them to their actual values by referencing the code book.   Renames columns to more descriptive names: Since original column name in 2022 BRFSS is complex, we will change names of columns into simpler strings.    2. Data Preprocessing      Handle duplicates, missing values   Handle records that have the values “Refused” or “Don’t know/Not sure”   Handle outliers which is our of range Q1 - 1.5 IQR and Q3 + 1.5 IQR   3. Model Building      Applies encoding and scaling to the data   Uses sampling methods to handle imbalanced datasets   Model Training: Defines a set of basic models (e.g., Decision Tree, Random Forest, Gradient Boosting, XGBoost, LightGBM). Fine-tuning on the best performing models and then compares them based on performance metrics and select the best one   4. Model Deploying      Load the best model from the pickle file   Uses the loaded model to make predictions on new data   Building a streamlit app to deploy the model online   Functionalities      predict type-2 diabetes probabilities of an individual from user input             determine which indicators are highly associated with type-2 diabetes             Demo   Web App     ","categories": [],
        "tags": [],
        "url": "/projects/project-Building%20a%20classification%20model%20to%20predict%20type-2%20diabetes/",
        "teaser": "/assets/obsidian/2b2c15a072165ff6293fa65fe74937c4.png"
      },{
        "title": "Building a local Q&A chatbot on custom dataset",
        "excerpt":"Business Scenario   The business scenario for this application is to provide a Q&amp;A chatbot running locally that can provide quick and accurate answers based on the content of the uploaded documents. This chatbot is ensure the information answering based on private provided materials, prevent hallucination, a common problem when using cloud-based large language models (LLM). Additionally, the uploaded file mad model are saved locally, ensuring the privacy of the data. Finally, the chat bot is free to use after setup because users don’t have to pay per API request.   Techniques   Streamlit: A framework for creating interactive web applications in Python. LangChain: A library for building language model applications. Ollama: A open-source framework for managing LLMs locally. LLM: DeepSeek R1 model, which is significant for chain-of-thought reasoning RAG: stand for Retrieval-Augmented Generation, an AI technique that combines retrieval-based and generative approaches to improve the accuracy and relevance of responses in language models.   Workflow   1. File upload  Users can upload files in PDF, DOCX, TXT, or CSV formats. The uploaded file is saved locally.  2. Document processing  Document loader modules to load documents in various formats. The document is split into chunks using  RecursiveCharacterTextSplitter HuggingFace embeddings are created for the document chunks. The document chunks are stored in a vector store (FAISS). A retriever is set up to perform similarity search on the vector store.  3. Query input  Users can input questions via text box.  4. Generating responses  Ollama DeepSeek R1 model is instantiated for generating responses based on A prompt template. A ConversationalRetrievalChain is created to handle question-answering with the LLM and retriever.  5. Response display  The response is displayed in three tabs: “Answer,” “Reasoning,” and “History.” Any errors during processing are caught and displayed as error messages. The app maintains a history of questions and responses in the session state.   Functionalities      Interactive Interface: The app provides an interactive interface with file upload on sidebar and chatbot question and answer on the main page               Support multiple format: Users can ask questions related to many format docucments such as pdf, docx, txt, csv                  Reasoning explanation: every answer is explained by chain of reasoning supported by Deepseek.         Conversational History: The app maintains a history of questions and answers, allowing users to review past interactions.            Work with tabular data         Demo     ","categories": [],
        "tags": [],
        "url": "/projects/project-Building%20a%20local%20Q&A%20chatbot%20on%20custom%20dataset/",
        "teaser": "/assets/obsidian/163dacc0795d369e7f58ab83d514b34d.png"
      }]
